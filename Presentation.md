# Presentation

## 三角化方法及 PnP 方法

### 实验背景

1. 单目图像缺乏直接深度信息
2. 多视角图像提供视差信息，可用于恢复三维结构
3. 三角化（Triangulation）是通过多个图像中匹配点与相机姿态反推出 3D 点的几何方法
4. 在视觉 SLAM、Structure-from-Motion 等任务中应用广泛

### 实验目标

利用图像序列与已知相机姿态进行三角化估计三维点

### 数据类型

**数据集 Whole-Apartment**

* **发布机构**：EPFL（瑞士联邦理工学院 Lausanne）
* **主要任务**：室内场景下的深度估计、三维重建、三角化精度分析等。
* **拍摄环境**：一个完整的住宅公寓（Whole Apartment）场景，涵盖多个房间（如客厅、卧室、厨房等）。
* **数据类型**：
  * 彩色图像（RGB）：深度图（Ground Truth Depth）
  * 相机位姿（Camera Poses）：内参（Intrinsics）

### 三角化原理

![](assets/2025-06-19_21-35-16.png)

![](assets/2025-06-09_06-42-11.png)

给定两个视角的相机投影矩阵：

![](assets/2025-06-09_06-38-56.png)

以及对应的图像点：

![](assets/2025-06-09_06-39-20.png)

目标是恢复三维点 X，三角化的数学核心是利用两个视角的对应像素点约束，通过解以下线性方程组求解齐次坐标 X：

![](assets/2025-06-09_06-39-39.png)

通过对上式用 SVD 求解最小奇异值对应的 X，得到三维点的齐次坐标，再归一化：

![](assets/2025-06-09_06-40-09.png)

得到：

![](assets/2025-06-09_06-40-29.png)

相机 1 坐标系下的深度即为 Z 值。

**三角测量依据的是同一个空间点在不同时刻的投影到相机成像平面上的位置来确定这两个时刻时这个点的深度。**

### 三角化流程

#### 深度图生成与误差评估

将三角化的 3D 点投影到第一帧图像中，将其 Z 值作为重建深度。

与真实深度图进行逐像素比较，计算以下误差指标：

* 相对绝对误差（Abs）
* 均方根误差（RMSE）
* 对数 RMSE（RMSE log）

#### 三角化重建

对匹配点进行像素归一化（使用内参 K 和 `cv2.undistortPoints`）。

构建两个投影矩阵：$P_1= K[I|0]$、$P_2= K[R|t]$

使用 OpenCV 的 `triangulatePoints` 获取三维点坐标。

对三维点进行齐次归一化，过滤掉无效（NaN 或距离过远）点。

#### 计算相对位姿

对每对连续帧 $(i,i+1)$，根据外参计算相对变换：

$$
T_{rel}=T_{i+1}+T_i^{-1}
$$

提取相对旋转 R 和平移向量 t。

#### 特征提取与匹配

使用以下三种方法进行特征提取与匹配：ORB（快速、二进制）、SIFT（尺度不变特征）、SURF（加速鲁棒特征）。

采用 BFMatcher 进行暴力匹配，ORB 使用 Hamming，其余方法使用 L2。

#### 加载相机参数

内参读取：解析焦距 $(f_x, f_y)$ 和主点 $(c_x, c_y)$，生成相机矩阵 K。

外参读取：每三行合成为一个 3×4 姿态矩阵，并扩展为 4×4 齐次矩阵。

### 三角化结果

| 方法 | Abs | RMSE | RMSE log |
| :---: | :---: | :---: | :---: |
| ORB | 1.474 | 3.301 | 1.504 |
| SIFT | 1.34 | 2.989 | 1.819 |
| SURF | 1.448 | 3.068 | 1.851 |

**三角化方法误差来源分析**

* 特征匹配误差
  * 受图像噪声、光照变化等影响，误匹配点参与三角化将导致空间误差。
  * 匹配精度不足（如亚像素级误差）会放大深度估计误差。
* 相对位姿与内参误差
  * 基线过短或视角变化小 → 视差不足，三角化条件不充分。
* 数值不稳定性
  * 极线附近匹配点或退化三角形 → 解空间不稳定、深度不可信。
  * 输出为相对深度 → 缺乏真实尺度，无法获取绝对深度。

### PnP 方法介绍

PnP 问题是指：在已知相机内参的前提下，给定若干个 3D 点及其在图像中的 2D 投影坐标，估计相机的姿态（位置和平移）。

**输入：**

* 相机内参矩阵 $K$
* 一组 3D 世界坐标点 $X_i$
* 对应的图像 2D 点 $x_i$

**输出：**

* 相机位姿：旋转矩阵 $R$、平移向量 $t$
* 得到从世界坐标系到相机坐标系的变换

![](assets/2025-06-09_06-52-58.png)

**使用 PnP 方法的优点：**

1. **姿态精度高**：PnP 基于已知的 3D 点和 2D 投影点（而不是从匹配点推导相对位姿），能提供更精确、稳定的相机位姿，特别在基线较小时更鲁棒。
2. **支持真实尺度恢复**：通过 PnP 得到的姿态可带入真实尺度，三角化出的深度也保持绝对尺度一致性。
3. **减少累积误差**：利用已知 3D 点做 PnP 得到准确位姿，再进行三角化可以限制误差传播，提高整体地图构建质量。
4. **鲁棒性强**：PnP 方法结合 RANSAC 使用，对特征点的误匹配具有较强的抗干扰能力。相比之下，直接三角化受误匹配和本质矩阵误差影响更大。
5. **适用于多帧融合**：可以在一个局部窗口中多帧联合优化 PnP 姿态，再统一进行三角化，提升深度估计稳定性（如 Sliding Window BA）。

### PnP 方法流程

#### 深度图生成与误差评估

将三角化的 3D 点投影到第一帧图像中，将其 Z 值作为重建深度。

与真实深度图进行逐像素比较，计算以下误差指标：

* 相对绝对误差（Abs）
* 均方根误差（RMSE）
* 对数 RMSE（RMSE log）

#### 三角化重建

对匹配点进行像素归一化（使用内参 K 和 `cv2.undistortPoints`）。

构建两个投影矩阵：$P_1= K[I|0]$、$P_2= K[R|t]$

使用 OpenCV 的 `triangulatePoints` 获取三维点坐标。

对三维点进行齐次归一化，过滤掉无效（NaN 或距离过远）点。

#### 位姿估计（PnP）

使用提取到的 3D-2D 点对，调用 OpenCV 的 `solvePnPRansac` 函数，估计第二张图像相对于第一张图像的旋转（R）和平移（t）；

设置迭代次数、投影误差阈值等参数以提高鲁棒性；

若 R 矩阵不合法或 t 过大，放弃该图像对。

#### 3D 点提取

对第一张图像的匹配点，根据深度图中的深度值和相机内参，将其反投影为三维空间中的点 $(X, Y, Z)$；

舍弃无效深度点或超出范围的点（如 $<0.1m$ 或 $>100m$）；

保留有效的 3D-2D 对应关系，为后续 PnP 准备数据。

#### 数据加载与特征提取与匹配

与三角化内容相同。

### PnP 方法后三角化结果及分析

![](assets/2025-06-09_06-58-42.png)

![](assets/2025-06-09_06-58-58.png)

| 方法 | Abs | RMSE | RMSE log | 点数 | 时间 |
| :---: | :---: | :---: | :---: | :---: | :---: |
| SIFT | 0.3206 | 0.4891 | 0.6600 | 206 | 0.10 |
| SURF | 0.3521 | 0.5157 | 0.7469 | 296 | 0.08 |
| ORB | 0.4899 | 0.5951 | 0.9530 | 886 | 0.06 |

* **精度方面**：SIFT 在所有三个误差指标（Abs、RMSE、RMSE log）上表现最佳，说明其特征点匹配更稳定，误差更小。SURF 次之，ORB 精度相对较低，特别是在对数误差方面（0.9530），表现出较明显的估计偏差。
* **鲁棒性方面**：ORB 能够提取更多的匹配点（有效点数高达 886），显著高于 SIFT 和 SURF，这说明 ORB 更适用于纹理丰富或图像噪声较大的场景。但也由于点数过多且不够精确，误差指标上偏高。
* **计算效率方面**：ORB 平均处理时间最低，仅为 0.06 秒/对，适合实时处理需求；SIFT 和 SURF 略慢，分别为 0.10 和 0.08 秒/对。
* **精度-效率权衡**：若关注深度估计精度，推荐使用 SIFT；若在实时性要求较高或大规模处理中使用，ORB 是较好的选择；SURF 作为折中方案，兼顾一定精度与效率。

## DELTAS 方法复现及改进

### DELTAS 方法简介

DELTAS 是一种高效的多视图深度估计算法，旨在在无需构建代价体（Cost Volume）的前提下实现准确、低计算成本的深度估计。传统基于代价体的多视图立体视觉方法尽管精度较高，但计算资源开销大，不适用于资源受限的场景，例如移动设备或 AR / VR 系统。为此，DELTAS 提出了一种三阶段的深度估计框架：

![](assets/2025-06-09_07-01-07.png)

#### 兴趣点检测与描述

输入图像经过图像编码器（Image Encoder）提取特征后，分别送入两个解码头：

* **Detector Decoder**：负责生成图像中的兴趣点热图（Interest Points）。
* **Descriptor Decoder**：输出每个像素位置的特征描述子张量（Descriptor Tensor）。

该模块与 SuperPoint 架构类似，但使用了更深的主干网络（如 ResNet-50），以增强下游密集深度估计能力。

相比上节提到的方法，主要有以下优势：

1. 使用 SuperPoint-like 网络端到端学习特征点与描述子，抗光照/尺度变化能力更强。
2. 提取过程通过图像上下文优化特征位置和分布，提高点的可重复性和准确率。
3. 训练目标包括匹配精度与兴趣点质量，提供鲁棒输入。

从而减小了误匹配点、光照变化、亚像素误差导致的三角化误差。

#### 点匹配与三角测量

目标图像中的兴趣点经过 Point Sampler 筛选，并提取对应的描述子。

利用相对位姿（Relative Pose），将兴趣点投影到辅助视角图像中，仅在其极线范围内进行描述子采样（Epipolar Sampler），显著减少匹配计算量。

匹配结果通过 Soft Matcher 得到多个视角下的点对。

所有匹配点被送入可微分的三角测量模块（Triangulation Module），通过代数解法估算每个兴趣点对应的三维坐标，最终生成稀疏的 3D 点云。

相比上节提到的方法，主要有以下优势：

1. 网络使用三视图构建多视角冗余，弥补小视差问题，通过加权 SVD 方法处理匹配点置信度，弱视角的图像贡献更少，增强稳定性。解决了如基线短、视差小，三角化不稳定的问题。
2. 使用可微分 SVD 解法实现稳健的线性三角测量，避免退化点对误差放大。匹配点位置通过 Softmax 加权平均，降低离散搜索点引入的数值跳变。从而减少了退化几何、极线附近匹配不可靠导致的数值不稳定性。

#### 稀疏到稠密深度补全

三角测量得到的稀疏深度图输入一个浅层的稀疏深度编码器（Sparse Depth Encoder），提取稀疏几何特征。

该特征与图像编码器输出特征一起输入到 U-Net 风格的深度解码器（Depth Decoder），最终输出完整的稠密深度图（Depth Image）。

整体训练过程为端到端，并在多个尺度上添加监督，提升预测精度与边缘细节还原能力。

相比上节提到的方法，主要有以下优势：

1. 结合图像和稀疏深度特征的 U-Net 结构完成高质量稠密预测。
2. 保留几何精度（来自三角化），融合图像上下文结构，提升边缘细节和连续性。
3. 支持多尺度监督、ASPP 模块增强结构理解。
避免了传统三角化输出点稀疏，无法用于完整深度估计的问题。

### 数据集处理

论文中提供的代码所使用的数据集格式与 whole_apartment 不符，我们对 whole_apartment 数据集进行以下处理：

**位姿划分**：whole_apartment 数据集位姿数据存储在一个 txt 文件中，而论文代码中每一张图片位姿数据都存储在一个单独的 txt 中，因此我们对 whole_apartment 数据集中的位姿数据进行了划分。

**图像重排序**：另外图片命名序号等也做了重新排列。

![](assets/2025-06-09_07-04-54.png)

![](assets/2025-06-09_07-06-12.png)

![](assets/2025-06-09_07-05-34.png)

![](assets/2025-06-09_07-05-58.png)

### 实验设计

**参数设计：**

| 序列长度 | 序列间隔 |
| :---: | :---: |
| 3 | 20 |
| 4 | 15 |
| 5 | 12 |
| 7 | 10 |

**参数设计原则：**

论文在 4.1 节提到：Three views from a scan at a fixed interval of 20 frames along with the pose and depth information forms a training data point in our method.

即每个样本由三帧图像组成，它们在原始视频序列中间隔 20 帧，用于构建锚帧 + 两参考帧的三视图结构，便于多视图匹配与三角化。

此外，论文中还提到：These gaps ensure that each set approximately spans similar volumes in 3D space, and any performance improvement emerges from the network better using the available information as opposed to acquiring new information.

虽然序列长度变多，但通过缩短帧间隔（gap），保持总视角跨度基本一致，以便公平比较更多视图是否对网络性能有提升。

### 实验数据

我们使用上述参数进行多轮测试，得到了以下数据：

![](assets/2025-06-09_07-09-37.png)

**实验数据分析：**

随着序列增长和帧间隔减小，各项指标均有略微下降，说明性能在改善，但是所需时间却大幅增加。

**进一步分析：**

1. 更长的序列（更多图像视角）和更小的间隔（更强的帧间几何约束）确实能提供更多冗余信息，有助于三角化得到更稳健的稀疏点，进而提升稠密深度图的质量；
2. 但提升有限，表明 DELTAS 在 seq=3、gap=20 时已有较强性能，对帧数和间隔不敏感，具备较好鲁棒性。
3. 应当平衡 seq_length（模型表现）与时间成本。

**实验结果分析：**

从表格数据可以看出，DELTAS 方法大部分指标均明显优于上节的三角化方法及 PnP 方法。由此说明在 whole_apartment 数据集上性能相比于三角化方法和 PnP 方法明显效果更加良好。

**与论文结果对比：**

![](assets/2025-06-19_21-47-28.png)

相比于论文中在 ScanNet 数据集上测试的数据，实验数据约在同一个数量级上，但是表现仍明显与论文在 ScanNet 数据集上的表现有较大差距。

分析：模型在未知环境下的泛化能力仍有待提升。

原因推测：在 DELTAS 中，三角化模块需要已知的相对相机位姿 (R, t) 来进行 Epipolar 约束与 3D 点恢复。这通常依赖外部的 SLAM 或 VIO 系统。然而，实际部署中存在两个问题:

1. VIO / SLAM 本身不够准确，会导致三角化误差放大；
2. 某些设备无法获得准确位姿（如普通单目相机），模型泛化受限。

### 改进 1

#### 改进目标

提高模型泛化能力。

#### 实现思路

引入可微图像重投影误差作为自监督信号，在训练阶段对三角化模块和姿态进行优化，从而摆脱对外部位姿输入的强依赖。

主要包括以下三个步骤：

1. 可微投影模型构建：利用三角化得到的 3D 点，通过当前估计的相机内外参，将 3D 点投影回二维视图。
2. 从参考图像中采样重建像素值与原图像中原像素比较。
3. 联合优化相对姿态和三角化参数。通过梯度回传优化描述子匹配位置，三角化过程本身，相对姿态等参数。

### 改进 2

#### 问题背景

深度图中常见在图像边缘（如物体边界）处预测模糊，网络在边缘处趋向过度平滑，丢失结构细节的问题。

#### 改进目标

1. 保持图像边缘处的深度跳变（物体之间的真实距离差）
2. 在平滑区域（背景、墙面）内继续保持平滑

#### 实现思路

计算像素之间深度差，但根据图像内容调整平滑力度:

1. 如果图像边缘明显，说明该位置属于结构边界 → 不强制平滑
2. 如果图像边缘变化小，则加强平滑，去除深度噪声

### DELTAS 复现结论

1. 在 whole_apartment 数据集上性能相比于三角化方法和 PnP 方法明显效果更加良好。
2. 增加帧数或减小帧间时间间隔对 DELTAS 性能有一定提升，但改善效果有限。
3. 在 whole_apartment 数据集上的性能下降明显，说明模型在未知环境下的泛化能力仍有待提升。

## 遇到的困难及解决方法

### PnP 方法和三角化估计阶段

1. **数据库获取困难**：下载速度极慢 / 不稳定。
2. **OpenCV 版本问题**：OpenCV 默认不支持 SIFT / SURF。
3. **三角化点全堆叠在一起**：三维点投影呈现一条线或扁平结构，无有效深度分布。图像对视觉差过小，难以反映深度。

### 复现初期模型表现远低于预期

#### 问题发现

在复现初期，我们发现 DELTAS 模型在 whole_apartment 数据集上的深度估计效果很差，如下所示：

![](assets/2025-06-09_07-16-13.png)

#### 问题排查

Whole Apartment 数据集中的深度图通常以 16 位无符号整数格式存储，其单位为毫米，但为了节省存储空间，部分数据实际被以 depth >> 3 的形式编码。

#### 解决办法

在数据预处理阶段对深度图执行右移三位（depth = depth >> 3），恢复真实深度数值后重新训练，模型性能显著改善，稀疏点和稠密预测结果均趋于正常。

### ScanNet 和 whole apaerment 数据集差距较大

#### 问题发现

ScanNet 和 whole apaerment 数据集在图片命名、位姿数据记录等格式差异较大。

#### 解决办法

我们编写了相应脚本对 whole apartment 数据集进行了统一格式化处理。

### 测试花费时间较长

#### 问题发现

测试选取了多种不同的参数组合，并且不同参数组合随着 seq_length 变大测试时间也在增加，在有限硬件资源下测试时间过长。

#### 解决办法

我们最终对原始图像和深度图进行了等比例压缩，将原本 640×480 的图像压缩为 320×240 大小，在现有硬件条件下缩短了测试时间。

## 总结与心得

### 理论结合实践深化理解

通过三角化与 PnP 实验，我们系统掌握了计算机视觉中几何方法估计深度的核心思想，加深了对本质矩阵、投影矩阵与坐标变换的理解，也认识到实际图像中的特征提取、匹配误差等对三角化质量的显著影响。

### 工程实现能力得到提升

整个项目中涉及 OpenCV、NumPy、Matplotlib 等多个工具的联合使用，这一过程锻炼了我们对图像处理流程、相机模型、坐标变换与可视化方法的综合运用能力。

### 深度学习模型复现带来成长

DELTAS 网络的复现经历了模型权重下载、依赖环境配置、图像预处理标准化、结果评估指标复现等技术挑战。通过查阅论文与代码，我们逐步掌握了神经网络在深度估计中的应用，获得了宝贵的实践经验。

### 对深度估计任务有了更全面认知

通过对比三角化、PnP 和 DELTAS 三种方法的优缺点，这为我们未来研究和应用提供了方向指引。